{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pseudo code\n",
    "\n",
    "---- PREPARE DATA BY SPLITTING INTO INCREMENTAL LOAD\n",
    "\n",
    "1. Convert to date data type\n",
    "if yy > 25 then:\n",
    "    Custom function to convert 20th century years dates to 1997 instead of 2097 using strftime\n",
    "else:\n",
    "    to_date\n",
    "\n",
    "2. Function to iteratively for count distinct yyyy-mm months:\n",
    "- dt = every date\n",
    "- append 1 day's data to df\n",
    "- save as '/date/csv_name' + dt + '.csv'\n",
    "- dateadd a day\n",
    "\n",
    "---- CONVERT EACH SAVED CSV FILE TO PARQUET AND SAVE IT TO 'LANDING' FOLDER\n",
    "\n",
    "---- BRONZE LAYER: ConformInterface\n",
    "1. Read parquet file from LANDING for a specific date and a schema.json\n",
    "2. Write a pyspark code to verify parquet schema vs mentioned schema in json.\n",
    "3. Move parquet file to BRONZE if verification is successful else throw error and stop processing.\n",
    "\n",
    "---- SILVER LAYER: StandardizeColumns\n",
    "1. Read parquet file from BRONZE for same specific date\n",
    "2. Add audit columns to spark dataframe\n",
    "3. Save dataframe to SILVER with same name and delete file in BRONZE\n",
    "\n",
    "---- GOLD LAYER: ChangeDataCapture\n",
    "1. Perform incremental load of only changed data\n",
    "\n",
    "---- MODEL SQL DATABASE SCHEMA, IT WILL ACT AS WAREHOUSE (EXPLORE OPTIONS FOR FREE TIER)    -dbdiagram.io, erdlab.io\n",
    "\n",
    "---- COPY GOLD DATA INTO SQL WAREHOUSE\n",
    "\n",
    "---- USE DBT FREE TIER TO INTEGRATE, ANY TRANSFORMATION, CREATE EXTRACT TABLES\n",
    "\n",
    "---- SERVE EXTRACT TABLE TO SERVING FOLDER AS CSV FOR ANALYSIS\n",
    "\n",
    "---- CREATE POWERBI DASHBOARD\n",
    "\n",
    "---- CREATE ML MODEL TO PREDICT FUTURE PRICES BASED ON DOMESTIC FACTORS SUCH AS MSP, PRODUCTION\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rice_path = 'datasets/daily_retail_price_Rice_upto-apr_2015.csv'\n",
    "df = spark.read.csv(rice_path, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+--------------+-----+\n",
      "|    Date|Centre_Name|Commodity_Name|Price|\n",
      "+--------+-----------+--------------+-----+\n",
      "|25-11-97|      DELHI|          Rice|   10|\n",
      "|25-11-97|     SHIMLA|          Rice|   12|\n",
      "|25-11-97|    LUCKNOW|          Rice|  6.5|\n",
      "|25-11-97|  AHMEDABAD|          Rice|   10|\n",
      "|25-11-97|     BHOPAL|          Rice|    9|\n",
      "+--------+-----------+--------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1 = df.groupBy('Centre_Name').agg(countDistinct('Date')).alias('no_of_dates')\n",
    "df1.toPandas().to_csv('locations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "252.47058823529412"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.withColumn(\"date_column\", to_date(df[\"Date\"], \"dd-MM-yy\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "suddata",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
